# -*- coding: utf-8 -*-
"""asl_train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1licb8EXb3tT4VVx2hKSI3ycbVo2H8ySi
"""

#Connect google drive
from google.colab import drive
drive.mount('/content/drive')

#Unzip the dataset
import zipfile
import os

zip_path = "/content/drive/MyDrive/asl/dataset.zip"
extract_path = "/content/dataset"

with zipfile.ZipFile(zip_path, "r") as zip_ref:
    zip_ref.extractall(extract_path)

#Imports
import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.applications import EfficientNetB3
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.optimizers import Adam

#Training setup
train_dir = "/content/dataset/dataset/asl_alphabet_train/asl_alphabet_train"

BATCH_SIZE = 256
IMG_SIZE = (224, 224)

train_dataset = image_dataset_from_directory(
    train_dir,
    label_mode='categorical',
    class_names=['A', 'B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','del','nothing','space','0','1','2','3','4','5','6','7','8','9'],    # Explicitly specify classes to include
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    validation_split=0.2,
    subset='training',
    seed=123
)

val_dataset = image_dataset_from_directory(
    train_dir,
    label_mode='categorical',
    class_names=['A', 'B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','del','nothing','space','0','1','2','3','4','5','6','7','8','9'],
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    validation_split=0.2,
    subset='validation',
    seed=123
)

base_model = EfficientNetB3(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
base_model.trainable = True
for layer in base_model.layers[:200]:
    layer.trainable = False


model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(39, activation='softmax')
])


model.compile(optimizer=Adam(learning_rate=0.00001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])


history = model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=30
)

#Save The Model
model.save('/content/asl_model.h5')